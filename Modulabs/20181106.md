## 개요
- 20181106 모두의 연구소 - DataLab 진행내용
- 딥러닝에 쓰이는 기본 선형대수
- [BoostedTree - cs.washington.edu](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)

## 정리 - 선형대수
- linearity의 정의?
    + f(ax+by) = f(ax) + f(by)
- 왜 `f(x) = ax + b` 를 linearity regression이라고 할까?
    + vector로 나타내었을떄 linearity함
- linearity combination
- indepedent, dependent - 확률에서도 나오는 개념 -> statistically dependent
- independent와 orthogonal
    + PCA , ICA
- eigenvalues and eigenvectors of a matrix 의 의미
    + **x** -> [**A**] -> **y** (y = 람다x)
    + 어떤 처리를 해도 같은 값이 나와? 이 시스템을 나타내는 고유한 성질을 나타내는 벡터를 찾자

## 정리 - BoostedTree
- Element