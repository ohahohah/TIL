# Python ìœ¼ë¡œ Web Scraping

- Web Scraping ì´ë€? ì›¹ í˜ì´ì§€ì—ì„œ íŠ¹ì • ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒ. ì‹ ë¬¸ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ğŸ“° âœ‚ï¸
  - ì¦‰, HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì„œ ì •ë³´ë¥¼ ì˜ë¼ë‚´ëŠ” ê²ƒ
1. URL ì„ ì‚¬ìš©í•´ Request í•´ì„œ HTML ì½”ë“œë¥¼ Responseë¡œ ê°€ì ¸ì˜¤ê¸°
  - requests íŒ¨í‚¤ì§€ ì‚¬ìš©
  - ì˜µì…˜. User-Agent ì‚¬ìš©í•´ì„œ chrome ì—ì„œ Request ë³´ë‚¸ ê²ƒì²˜ëŸ¼
2. HTML code ì—ì„œ ë‚´ê°€ ì›í•˜ëŠ” ìš”ì†Œ element ë§Œ ê°€ì ¸ì˜´
  - DOM êµ¬ì¡° ì‚¬ìš© (ì˜ˆ. body > h1)
  - Selector ì‚¬ìš© (ì˜ˆ. #news)
  - BeautifulSoup4 íŒ¨í‚¤ì§€ ì‚¬ìš©


## ì´ˆ ê°„ë‹¨ ìŠ¤í¬ë˜í•‘ ì˜ˆì œ
- DOM êµ¬ì¡° ì´í•´í•˜ë©° ìš”ì†Œ ì°¾ì•„ë‚´ê¸°
- Chrome ê°œë°œìë„êµ¬ Inspector ì‚¬ìš©
[https://elastic-hugle-d528b6.netlify.app/demo/simple.html](https://elastic-hugle-d528b6.netlify.app/demo/simple.html)

```python
import requests
from bs4 import BeautifulSoup

# Request ì„¤ì •ê°’(HTTP Msg) - Desktop Chrome ì¸ ê²ƒì²˜ëŸ¼ 
headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}
url = 'https://elastic-hugle-d528b6.netlify.app/demo/simple.html'

# URL request í•´ì„œ HTML ì½”ë“œë¥¼ response ë°›ìŒ.
data = requests.get(url, headers=headers)
# print(data.text)

# BeautifulSoup4 ì‚¬ìš©í•´ì„œ html ìš”ì†Œì— ê°ê° ì ‘ê·¼í•˜ê¸° ì‰½ê²Œ ë§Œë“¦.
soup = BeautifulSoup(data.text, 'html.parser')
# print(soup)
# data.text ì™€ soup ì€ íƒ€ì…ì´ ë‹¤ë¦…ë‹ˆë‹¤! ì ‘ê·¼ì‰½ê²Œ í˜•íƒœë¥¼ ë°”ê¿ˆ.
# print(f'data.text: {type(data.text)} / soup : {type(soup)}')

# HTMLì˜ íŠ¹ì • elementìš”ì†Œë§Œ ê°€ì§€ê³  ì˜´. 
p_el = soup.select_one('body > p')
# print(p_el)
# print('textë§Œ ê°€ì ¸ì˜¤ê¸°:' + p_el.text)

# selector ì´ìš© - id ëŠ” ìœ ì¼í•˜ë¯€ë¡œ ë” í™•ì‹¤!  
news_el = soup.select_one('#news')
# print(news_el)
# print('textë§Œ ê°€ì ¸ì˜¤ê¸°:' + news_el.text)

# ì—¬ëŸ¬ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° 
div_els = soup.select('div')
# print(div_els)
# textë§Œ ê°€ì ¸ì˜¤ê¸°
# for div_el in div_els:
#     print(div_el.text)

# ì—¬ëŸ¬ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° - selector class
cool_els = soup.select('.cool')
# print(cool_els)
# # textë§Œ ê°€ì ¸ì˜¤ê¸°
# for cool_el in cool_els:
#     print(cool_el.text)

# ì²«ë²ˆì§¸ ìš”ì†Œë§Œ ê°€ì ¸ì˜¤ê²Œ ë¨
first_div_els = soup.select_one('div')
# print(first_div_els)
# print(first_div_els.text)

# copy selector ì‚¬ìš© - div 4ë²ˆì§¸ ìì‹ ìš”ì†Œ
we_cool_el = soup.select_one('body > div:nth-child(4)')
# print(we_cool_el)
# print(we_cool_el.text)


```


## ë”°ë¦‰ì´ í˜ì´ì§€ë¡œ ì •ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
ğŸ”¥  ë¬¸ì œ ë¶„ì„ ë¨¼ì €!

- ìš°ë¦¬ëŠ” ì•„ë˜ ğŸš² ë”°ë¦‰ì´ í˜ì´ì§€ì—ì„œ ë”°ë¦‰ì´ ì •ë³´ë¥¼  ìŠ¤í¬ë˜í•‘ í•´ì˜¬ ê±°ì—ìš”.
[https://elastic-hugle-d528b6.netlify.app/demo/bikeinfo.html](https://elastic-hugle-d528b6.netlify.app/demo/bikeinfo.html)

- ë§Œì•½ ë”°ë¦‰ì´ API ì •ë³´ê°€ ì œê³µë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ë ‡ê²Œ ì›¹ í˜ì´ì§€ì—ì„œ ì§ì ‘ ì •ë³´ë¥¼ ê¸ì–´ì„œ ê°€ì ¸ì™€ì•¼í•˜ì£ .
- ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì°¨ë¡€ëŒ€ë¡œ ì•„ë˜ ì •ë³´ë“¤ì„ ê°€ì ¸ì˜¬ ê±°ì—ìš”.
    - ê±°ì¹˜ëŒ€ ìœ„ì¹˜ 'ë“¤'
    - ê° ê±°ì¹˜ëŒ€ ë³„ ê±°ì¹˜ëŒ€ ìˆ˜
    - í˜„ì¬ ê±°ì¹˜ëœ ë”°ë¦‰ì´ ìˆ˜

1. í…œí”Œë¦¿ì—ì„œë¶€í„° ì‹œì‘í•©ì‹œë‹¤.
- `[Tutorials.py](http://tutorials.py)` ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë§Œë“¤ì–´ë³¼ê²Œìš”.

    [ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 01] í…œí”Œë¦¿
    ```python
    # requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
    import requests
    from bs4 import BeautifulSoup

    # ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

    # GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
    data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

    # BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
    soup = BeautifulSoup(data.text, 'html.parser')
    ```

- ì´ í˜•íƒœëŠ” ëŒ€ë¶€ë¶„ ìŠ¤í¬ë˜í•‘ ì‹œì‘í•  ë•Œ ë¨¼ì € í•´ì£¼ì–´ì•¼í•˜ëŠ” ê²ƒë“¤! í…œí”Œë¦¿ ì´ë¼ê³  ê¸°ì–µí•´ë‘ì‹œë©´ ì¢‹ì•„ìš”.

2. ìŠ¤í¬ë˜í•‘ì—ì„œë„ select í•´ì˜¨ë‹¤! 

- í™”ë©´ì˜ elements ë¥¼ ì„ íƒ(select) í•´ì„œ ê°€ì ¸ì˜¤ëŠ” ê±´ ìŠ¤í¬ë˜í•‘ë„ ë˜‘ê°™ì•„ìš”.
    - html ì˜ parent-children (ë¶€ëª¨-ìì‹) ì¸ tree êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ìˆìœ¼ë©´ í¸í•©ë‹ˆë‹¤!
- ë¨¼ì € ê°€ì ¸ì˜¬ ë¶€ë¶„ì„ chrome ê°œë°œìë„êµ¬  Inspect ë¡œ í™•ì¸í•´ë³¼ê¹Œìš”? í…Œì´ë¸” ë¶€ë¶„ì„ ì„ íƒí•´ë³´ì„¸ìš”. **íŠ¹ì§•ì´ ë  ë§Œí•œ ë¶€ë¶„ì´ ë­ê°€ ìˆì„ê¹Œìš”?** id? class? êµ¬ì¡°?

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 02] select íƒêµ¬í•˜ê¸°

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos = soup.select('#bike-info')
print(infos)
```
- ì´ í˜ì´ì§€ì—ì„œ ìœ ì¼í•œ ë¶€ë¶„ (id ì´ë‹ˆê¹Œìš”!) ì¸ ì •ë³´ ë³´ëŠ” í˜ì´ì§€ë¥¼ ê°€ì ¸ì™”ì–´ìš”.

3. ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì •ë³´ì— ë” ê°€ê¹Œì´ ì¢í˜€ë‚˜ê°€ë´…ì‹œë‹¤. 
- ìì£¼ ì“°ì´ëŠ” í•¨ìˆ˜ì¸ select_one ê³¼ select ì— ëŒ€í•´ì„œë„ íƒêµ¬í•´ë³´ì£ .

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 03] select_one ê³¼ select

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos = soup.select('#bike-info > tr')
print(infos)

# select í•¨ìˆ˜ë¥¼ ì“°ë‹ˆ ì—¬ê¸°ì— í•´ë‹¹ë˜ëŠ” ëª¨ë“  tagë“¤ì´ return ë˜ë„¤ìš”!
# print(infos[0])

# select_one í•¨ìˆ˜ë¥¼ ì“°ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”? 
# info_one = soup.select_one('#bike-info> tr')
# print(info_one) # ë§¨ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ê±° ë”± í•˜ë‚˜ì˜ ê°’ë§Œ ê°€ì ¸ì™€ìš”. ê·¸ë˜ì„œ ì´ë¦„ì´ one

```

4. ë¬¸ì œëŠ” í•œ ë²ˆì— í•˜ë‚˜ì”© ì ‘ê·¼! ê±°ì¹˜ëŒ€ ìœ„ì¹˜ ì •ë³´ë§Œ ê°€ì ¸ì™€ë³¼ê²Œìš”.

- ë°©ë²•ì€ í•˜ë‚˜ë§Œ ìˆëŠ” ê²Œ ì•„ë‹ˆëë‹ˆë‹¤!

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 04-1] classëª…ìœ¼ë¡œ ì ‘ê·¼í•˜ê¸°

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

stations = soup.select('.station')
print(stations)
```

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 04-2] infos  í™œìš©í•´ ì ‘ê·¼í•˜ê¸°

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos = soup.select('#bike-info > tr')
print(infos)

for info in infos:
#    print(info)    # info ê°€ ë¬´ì–¼ì§€ ëª¨ë¥´ê² ë‹¤ë©´ ì¶œë ¥í•´ë³´ë©´ ë©ë‹ˆë‹¤ 

    station_tag = info.select_one('.station')
    station = station_tag.text
# ìœ„ ë‘ ì¤„ì„ ì•„ë˜ì²˜ëŸ¼ ì¤„ì—¬ì“¸ ìˆ˜ë„ ìˆì–´ìš”
#    station = info.select_one('.station').text

     print(station)

```

5. ê±°ì¹˜ëŒ€ ìˆ˜ ê°€ì ¸ì™€ë³´ê¸°

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 05] 

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos = soup.select('#bike-info > tr')
print(infos)

for info in infos:
    station = info.select_one('.station').text
    rack = info.select_one('.rack').text

    print(station, rack)
```

- í˜¹ì‹œ íŒ¨í„´ì´ ë³´ì´ì‹œë‚˜ìš”? ë‹¤ì‹œ í•œë²ˆ í•´ ë³¼ê¹Œìš”?

6. í˜„ì¬ ì£¼ì°¨ë˜ì–´ìˆëŠ” ë”°ë¦‰ì´ ìˆ˜ ê°€ì ¸ì™€ë³´ê¸° 

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 06] 

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos = soup.select('#bike-info > tr')
print(infos)

for info in infos:
    station = info.select_one('.station').text
    rack = info.select_one('.rack').text
    parking = info.select_one('.parking').text

    print(station, rack, parking)
```

7.  íŒŒë€ ê¸€ì”¨ ë¶€ë¶„ë“¤ì˜ ê±°ì¹˜ëŒ€ ì´ë¦„,  ê±°ì¹˜ëŒ€ ìˆ˜, ë‚¨ì€ ë”°ë¦‰ì´ ìˆ˜ ê°€ì ¸ì˜¤ê¸°

[ğŸ’» ì½”ë“œ - íŠœí† ë¦¬ì–¼ 07] 

```python
# requestsì™€ bs4 íŒ¨í‚¤ì§€ ì‚¬ìš©í•  ê±°ì•¼
import requests
from bs4 import BeautifulSoup

# ë°ìŠ¤í¬í†± í¬ë¡¬ì¸ê²ƒëŸ¼ ìš”ì²­ - ê¸°ê¸°ë§ˆë‹¤ ëœ¨ëŠ” ì›¹í˜ì´ì§€ê°€ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ëª¨ë°”ì¼ê³¼ ë°ìŠ¤í¬íƒ‘ ì ‘ì†í•  ë•Œ ëª¨ì–‘ ë‹¤ë¥´ì£ ?
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

# GET ìš”ì²­ì´ë¼ get í•¨ìˆ˜
data = requests.get('https://amazing-wiles-4ebf2c.netlify.app/scraping/bikeinfo.html', headers=headers)

# BeautifulSoup í˜•íƒœë¡œ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ parsing
soup = BeautifulSoup(data.text, 'html.parser')

infos_like = soup.select('#bike-info > tr.like')
# print(infos_like)    # ë¨¼ì € ì¶œë ¥í•´ì„œ í™•ì¸

for info in infos_like:
    station = info.select_one('.station').text
    rack = info.select_one('.rack').text
    parking = info.select_one('.parking').text

    print(station, rack, parking)
```
